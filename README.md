# AI Doctor with Vision and Voice

## Overview
AI Doctor with Vision and Voice is an AI-powered health assistant that takes voice input from patients, processes medical images, and provides diagnostic insights with speech-based responses. It integrates **speech recognition**, **image analysis**, and **text-to-speech** functionalities.

## Features
- ğŸ¤ **Speech Recognition**: Converts patient audio input to text using **Groq Whisper API**.
- ğŸ¥ **Medical Image Analysis**: Uses **LLaMA-3.2 Vision** to analyze medical images and provide diagnostic insights.
- ğŸ”Š **AI Doctor Response**: Generates professional doctor-like responses.
- ğŸ” **Text-to-Speech**: Converts AI doctor's response into audio using **Google TTS, ElevenLabs, and Edge TTS**.
- ğŸŒ **Gradio UI**: Provides an interactive web interface for easy usage.

## Installation
### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/tirthosaha69/health-agentic-ai.git
cd health-agentic-ai
```
### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```
### 3ï¸âƒ£ Set Up Environment Variables
Create a `.env` file and add your API keys:
```
GROQ_API_KEY=your_groq_api_key
```

## Usage
### Run the Application
```bash
python gradio_app.py
```
### Gradio Interface
The app runs locally. Open the displayed **localhost URL** in your browser.

## Project Structure
```
health_agentic_ai/
â”‚â”€â”€ main.py                # Gradio interface and core functionality
â”‚â”€â”€ brain_of_the_doctor.py # Image encoding & AI-based medical analysis
â”‚â”€â”€ voice_of_the_doctor.py # Text-to-speech (TTS) processing
â”‚â”€â”€ voice_of_the_patient.py # Speech recognition (STT) and recording
â”‚â”€â”€ requirements.txt       # Dependencies
â”‚â”€â”€ .env                   # API keys and environment variables
```

## How It Works
1. **User speaks into the microphone** ğŸ¤
2. **Speech is transcribed** into text using Groq Whisper
3. **If an image is provided**, it is analyzed using LLaMA-3 Vision
4. **Doctor-like response is generated** with AI
5. **Response is converted into speech** using TTS models
6. **User receives both text and audio responses**

## Future Improvements ğŸš€
- Integrate **multilingual support** for broader accessibility.
- Enhance **diagnostic accuracy** with additional AI models.
- Deploy the app using **Flask/Django for production**.

## Contributing ğŸ¤
Pull requests are welcome! Open an issue for bug reports or feature requests.

## License ğŸ“
This project is licensed under the **MIT License**.

